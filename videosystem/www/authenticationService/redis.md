### redis 常见面试题

#### redis vs mencache

共同点：
    都是基于内存的数据库，一般都用来当做缓存使用。
    都有过期策略。
    两者的性能都非常高。
Redis 与 Memcached 区别：
    Redis 支持的数据类型更丰富（String、Hash、List、Set、ZSet），而 Memcached 只支持最简单的 key-value 数据类型；
    Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用，而 Memcached 没有持久化功能，数据全部存在内存之中，Memcached 重启或者挂掉后，数据就没了；
    Redis 原生支持集群模式，Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；
    Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持；
    #为什么用 Redis 作为 MySQL 的缓存？

#### redis 特点
    - Redis 具备高性能  原因是基于内存操作
    - Redis 具备高并发  单台设备的 Redis 的 QPS（Query Per Second，每秒钟处理完请求的次数） 是 MySQL 的 10 倍，Redis 单机的 QPS 能轻松破 10w，而 MySQL 单机的 QPS 很难破 1w。

#### redis 数据结构以及应用场景
在Redis中，虽然所有的数据类型在底层都是以字符串（二进制安全的字符串）存储，但是通过不同的命令和操作，我们可以以不同的逻辑类型来操作这些数据。对于每种数据结构，我们可以再具体探讨可以存储的值类型和相关操作。

### 1. 字符串（String）

- **键（Key）**：字符串。
- **值（Value）**：虽然在Redis内部，所有的值都是以字符串的形式存储的，你可以存储任何数据作为字符串的值，包括文本、整数、浮点数，甚至是二进制数据（如图片或序列化的对象）。
- **常用命令**：
  - 使用 `SET key value` 存储字符串，`value` 可以是包括整数、浮点数、文本等任何形式的字符串。
  - 使用 `GET key` 获取值，无论其原始类型如何，都将作为字符串返回。
  - 使用 `INCR key` 和 `DECR key` 对存储的数值进行增减操作，这意味着虽然存储的是字符串，但Redis允许你对其进行数值操作。
- **类型灵活性**：虽然基础存储单位是字符串，Redis可以灵活地对待这些字符串为特定类型，例如进行数值运算。

### 2. 哈希（Hash）

- **键（Key）**：字符串。
- **值（Value）**：字段（field）和值（value）对，其中字段和值都是字符串形式，但可以代表不同类型的数据。
- **常用命令**：
  - `HSET key field value` 中的 `value` 可以是字符串表现形式的任何数据，如整数、浮点数或文本。
  - `HGET key field` 获取的值以字符串形式返回，但可以代表任何数据类型。
- **应用场景**：通常用于存储对象的多个属性，例如用户信息（姓名、年龄等）。

### 3. 列表（List）

- **元素类型**：列表中的元素均为字符串类型，但字符串可以表示任何数据。
- **常用命令**：
  - `LPUSH key value` 和 `RPUSH key value` 中的 `value`，尽管是字符串，但可以是代表任何数据类型的字符串，如整数、文本。
  - 列表元素可以是序列化的复杂数据，例如JSON字符串。
- **应用场景**：列表通常用于实现队列和栈等数据结构。

### 4. 集合（Set）

- **元素类型**：集合中的每个元素都是不重复的字符串，字符串可以表示任何数据类型。
- **常用命令**：
  - `SADD key member`，`member` 可以是任意数据的字符串表现形式，如数字或文本。
  - `SMEMBERS key` 返回的每个元素都是字符串，尽管原始数据可能有不同的逻辑类型。
- **应用场景**：集合适合存储不需要排序且无重复的元素列表。

### 5. 有序集合（Sorted Set）

- **元素类型**：每个元素都是字符串，与一个浮点数分数关联。
- **常用命令**：
  - `ZADD key score member`，其中 `member` 是字符串，可以表示任何类型的数据。
  - `ZRANGE key start stop [WITHSCORES]` 返回的元素是字符串，分数用来进行排序。
- **应用场景**：适用于需要排序的场景，如排行榜。

总结来说，虽然Redis在存储时将所有数据类型视为字符串，但你可以通过Redis提供的不同命令来操作这些数据，就像它们是特定的数据类型一样。这种灵活性使得Redis能够适应多种不同的应用场景。

在使用Redis作为缓存时，合理的键（key）命名非常关键，它不仅影响到数据的组织和检索效率，还关系到缓存的维护和扩展性。合理的键命名策略可以帮助开发和维护团队更好地管理和利用缓存数据。以下是一些设计Redis键命名的常见原则和最佳实践：

### 1. **明确和描述性**
键名应当直观和描述性强，使得其他开发人员能够轻易理解键所存储的数据内容。例如，如果存储用户信息，键可以命名为`user:1234`，其中`1234`是用户ID。

### 2. **结构化命名**
采用一致的结构化格式，如使用冒号`:`分隔不同的命名段。这种方式有助于模块化和层次化数据，便于管理和访问。例如：
- `user:profile:1234`
- `product:details:5678`

### 3. **避免过长的键名**
虽然Redis的键名可以非常长，但实际使用中应避免过长的键名，因为长键名会消耗更多内存，并且在网络传输中也可能降低效率。尽量保持键名简洁。

### 4. **使用易于区分的命名空间**
命名空间类似于编程中的命名空间，通过前缀区分不同的数据类型或应用模块，这有助于数据的归类和权限控制。例如：
- `cache:session_tokens`
- `cache:user_profiles`

### 5. **避免敏感信息**
不要在键名中直接使用敏感信息，如用户的电子邮件地址、社会安全号等，这些信息应该通过某种方式加密或哈希处理。

### 6. **考虑使用哈希标签**
在使用集群时，相关的数据可以使用相同的哈希标签确保它们存储在同一个节点上。例如：`{user1000}:follows` 和 `{user1000}:followers` 可以确保两者在同一个哈希槽。

### 示例

假设你在一个电商平台使用Redis来缓存商品信息和用户会话，可以使用如下键命名策略：

- **商品信息**：`product:info:1234` 其中 `1234` 是商品ID。
- **用户会话**：`session:user:5678` 其中 `5678` 是用户ID。

这样的命名不仅清晰表明了缓存内容的类型（商品信息、用户会话），还通过ID指明了具体实体，同时保持了键名的简洁性。

通过这些策略，你的Redis缓存键将会更加有组织，更易于管理和扩展。

#### 单线程

Redis 单线程指的是「接收客户端请求->解析请求 ->进行数据读写等操作->发送数据给客户端」这个过程是由一个线程（主线程）来完成的，这也是我们常说 Redis 是单线程的原因。

虽然 Redis 的主要工作（网络 I/O 和执行命令）一直是单线程模型，但是在 Redis 6.0 版本之后，也采用了多个 I/O 线程来处理网络请求，这是因为随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在网络 I/O 的处理上。

所以为了提高网络 I/O 的并行度，Redis 6.0 对于网络 I/O 采用多线程来处理。但是对于命令的执行，Redis 仍然使用单线程来处理，所以大家不要误解 Redis 有多线程同时执行命令。

##### Redis 采用单线程为什么还这么快？
- Redis 的大部分操作都在内存中完成，并且采用了高效的数据结构，因此 Redis 瓶颈可能是机器的内存或者网络带宽，而并非 CPU，既然 CPU 不是瓶颈，那么自然就采用单线程的解决方案了；
- Redis 采用单线程模型可以避免了多线程之间的竞争，省去了多线程切换带来的时间和性能上的开销，而且也不会导致死锁问题。
- Redis 采用了 I/O 多路复用机制处理大量的客户端 Socket 请求，IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听 Socket 和已连接 Socket。内核会一直监听这些 Socket 上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。


#### 持久化
Redis 共有三种数据持久化的方式：
- AOF 日志：每执行一条写操作命令，就把该命令以追加的方式写入到一个文件里；
- RDB 快照：将某一时刻的内存数据，以二进制的方式写入磁盘；
- 混合持久化方式：Redis 4.0 新增的方式，集成了 AOF 和 RBD 的优点；
#### AOF 日志
- 实现方法：Redis 在执行完一条写操作命令后，就会把该命令以追加的方式写入到一个文件里，然后 Redis 重启时，会读取该文件记录的命令，然后逐一执行命令的方式来进行数据恢复。（注意顺序，先写入库，再写入日志），可能会造成数据丢失（更改后没有及时落盘）和可能阻塞后续的操作（由于写操作命令执行成功后才记录到 AOF 日志，所以不会阻塞当前命令的执行，但因为 AOF 日志也是在主线程中执行，所以当 Redis 把日志文件写入磁盘的时候，还是会阻塞后续的操作无法执行。）
- 写回策略：（日志落盘策略）
    always: 每次写操作命令执行完后，同步将 AOF 日志数据写回硬盘；
    everysec: 次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，然后每隔一秒将缓冲区里的内容写回到硬盘；
    no:由 Redis 控制写回硬盘的时机，转交给操作系统控制写回的时机，也就是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，再由操作系统决定何时将缓冲区内容写回硬盘。
- AOF 重写机制
    why: Redis 为了避免 AOF 文件越写越大，提供了 AOF 重写机制，当 AOF 文件的大小超过所设定的阈值后，Redis 就会启用 AOF 重写机制，来压缩 AOF 文件。
    how: 在使用重写机制后，就会读取 name 最新的 value（键值对） ，然后用一条 「set name xiaolincoding」命令记录到新的 AOF 文件，之前的第一个命令就没有必要记录了，因为它属于「历史」命令，没有作用了。这样一来，一个键值对在重写日志中只用一条命令就行了。
    怎么解决数据不一致的问题：但是重写过程中，主进程依然可以正常处理命令，那问题来了，重写 AOF 日志过程中，如果主进程修改了已经存在 key-value，那么会发生写时复制，此时这个 key-value 数据在子进程的内存数据就跟主进程的内存数据不一致了，这时要怎么办呢？

    为了解决这种数据不一致问题，Redis 设置了一个 AOF 重写缓冲区，这个缓冲区在创建 bgrewriteaof 子进程之后开始使用。
#### RDB 快照是如何实现的呢？
    why: 
    因为 AOF 日志记录的是操作命令，不是实际的数据，所以用 AOF 方法做故障恢复时，需要全量把日志都执行一遍，一旦 AOF 日志非常多，势必会造成 Redis 的恢复操作缓慢。

    为了解决这个问题，Redis 增加了 RDB 快照。所谓的快照，就是记录某一个瞬间东西，比如当我们给风景拍照时，那一个瞬间的画面和信息就记录到了一张照片。

    所以，RDB 快照就是记录某一个瞬间的内存数据，记录的是实际数据，而 AOF 文件记录的是命令操作的日志，而不是实际的数据。

    因此在 Redis 恢复数据时， RDB 恢复数据的效率会比 AOF 高些，因为直接将 RDB 文件读入内存就可以，不需要像 AOF 那样还需要额外执行操作命令的步骤才能恢复数据。
    how:
        save 主线程生成 RDB 文件，会阻塞主线程
        bgsave 子进程来生成 RDB 文件，这样可以避免主线程的阻塞；
        配置文件配置bgsave： 某段时间内执行了多少次写操作来触发
    QA:RDB 在执行快照的时候，数据能修改吗？
        yes.执行 bgsave 过程中，Redis 依然可以继续处理操作命令的，也就是数据是能被修改的，关键的技术就在于写时复制技术（Copy-On-Write, COW）
#### 混合持久化
    why:
        RDB 优点是数据恢复速度快，但是快照的频率不好把握。频率太低，丢失的数据就会比较多，频率太高，就会影响性能。

        AOF 优点是丢失数据少，但是数据恢复不快。

        为了集成了两者的优点， Redis 4.0 提出了混合使用 AOF 日志和内存快照，也叫混合持久化，既保证了 Redis 重启速度，又降低数据丢失风险。
    how:
        混合持久化工作在 AOF 日志重写过程，当开启了混合持久化时，在 AOF 重写日志时，fork 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件，然后主线程处理的操作命令会被记录在重写缓冲区里，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。
    goooood:
        混合持久化结合了 RDB 和 AOF 持久化的优点，开头为 RDB 的格式，使得 Redis 可以更快的启动，同时结合 AOF 的优点，有减低了大量数据丢失的风险。
    baaaaad:
        AOF 文件中添加了 RDB 格式的内容，使得 AOF 文件的可读性变得很差；
        兼容性差，如果开启混合持久化，那么此混合持久化 AOF 文件，就不能用在 Redis 4.0 之前版本了。
#### 集群设置
    主从复制
        读写分离，避免数据不一致的问题
        实现过程：主服务器可以进行读写操作，当发生写操作时自动将写操作同步给从服务器，而从服务器一般是只读，并接受主服务器同步过来写操作命令，然后执行这条命令。
        命令：
            假设有两台服务器AB，设置主从服务器的命令如下：
            设置B服务器为A服务器的从服务器（A主B从）
            在B服务器执行命令：replicaof A:IP A:port   第一次同步
            其中第一次同步分为三个阶段：
                第一阶段是建立链接、协商同步；
                第二阶段是主服务器同步数据给从服务器；
                第三阶段是主服务器发送新写操作命令给从服务器。
            主从服务器在完成第一次同步后，就会基于长连接进行命令传播。
            长连接命令基于网络，保持数据一致性如下方式：
                在网络断开重连时，主从服务器采用增量复制的方式继续同步（网络断开期间主服务器接收到的写操作命令），关键设置：repl_backlog_buffer 
        总结
            主从复制共有三种模式：全量复制、基于长连接的命令传播、增量复制。

            主从服务器第一次同步的时候，就是采用全量复制，此时主服务器会两个耗时的地方，分别是生成 RDB 文件和传输 RDB 文件。为了避免过多的从服务器和主服务器进行全量复制，可以把一部分从服务器升级为「经理角色」，让它也有自己的从服务器，通过这样可以分摊主服务器的压力。

            第一次同步完成后，主从服务器都会维护着一个长连接，主服务器在接收到写操作命令后，就会通过这个连接将写命令传播给从服务器，来保证主从服务器的数据一致性。

            如果遇到网络断开，增量复制就可以上场了，不过这个还跟 repl_backlog_size 这个大小有关系。

            如果它配置的过小，主从服务器网络恢复时，可能发生「从服务器」想读的数据已经被覆盖了，那么这时就会导致主服务器采用全量复制的方式。所以为了避免这种情况的频繁发生，要调大这个参数的值，以降低主从服务器断开后全量同步的概率。
        tips:
            读写分离是应用层实现的。
            怎么判断 Redis 某个节点是否正常工作？
                心跳机制：
                    主--->从   默认每隔10秒发送ping命令，参数repl-ping-slave-period（配置文件中的参数）
                    从--->主   每隔1秒发送replconf ack 命令，为了
                                上报自身偏移量，检测数据是否丢失
                业务实现过程：
                    部署时，应确保所有redis节点配置文件正确配置
                    监控：  自带监控命令： info replication 
            主从复制架构中，过期key如何处理？
                主节点处理了一个key或者通过淘汰算法淘汰了一个key，这个时间主节点模拟一条del命令发送给从节点，从节点收到该命令后，就进行删除key的操作。
            Redis 是同步复制还是异步复制？
                Redis 主节点每次收到写命令之后，先写到内部的缓冲区，然后异步发送给从节点。
                因为是异步复制，此时业务中要保证考虑到复制延迟的问题
                1. 使用wait 命令，eg: wait 1 1000 等待至少1个从服务器，在1000毫秒内确认接收数据
                2. 极高数据一致性的数据，读写操作都在主节点进行
                外部保证：
                    尽量保证网络连接状态良好
            异步复制同步丢失
                对于 Redis 主节点与从节点之间的数据复制，是异步复制的，当客户端发送写请求给主节点的时候，客户端会返回 ok，接着主节点将写请求异步同步给各个从节点，但是如果此时主节点还没来得及同步给从节点时发生了断电，那么主节点内存中的数据会丢失。
    哨兵模式
        哨兵机制是如何工作的？
            哨兵其实是一个运行在特殊模式下的 Redis 进程，所以它也是一个节点。从“哨兵”这个名字也可以看得出来，它相当于是“观察者节点”，观察的对象是主从节点。
            监控、选主、通知。
        如何判断主节点真的故障了
            哨兵会每隔 1 秒给所有主从节点发送 PING 命令，当主从节点收到 PING 命令后，会发送一个响应命令给哨兵，这样就可以判断它们是否在正常运行。如果主节点或者从节点没有在规定的时间内响应哨兵的 PING 命令，哨兵就会将它们标记为「主观下线」。这个「规定的时间」是配置项 down-after-milliseconds 参数设定的，单位是毫秒。

            所以，为了减少误判的情况，哨兵在部署的时候不会只部署一个节点，而是用多个节点部署成哨兵集群（最少需要三台机器来部署哨兵集群），通过多个哨兵节点一起判断，就可以就可以避免单个哨兵因为自身网络状况不好，而误判主节点下线的情况。同时，多个哨兵的网络同时不稳定的概率较小，由它们一起做决策，误判率也能降低。

            前面说过，为了更加“客观”的判断主节点故障了，一般不会只由单个哨兵的检测结果来判断，而是多个哨兵一起判断，这样可以减少误判概率，所以哨兵是以哨兵集群的方式存在的。

            哪个哨兵节点判断主节点为「客观下线」，这个哨兵节点就是候选者，所谓的候选者就是想当 Leader 的哨兵。
        总结
            Redis 在 2.8 版本以后提供的哨兵（Sentinel）机制，它的作用是实现主从节点故障转移。它会监测主节点是否存活，如果发现主节点挂了，它就会选举一个从节点切换为主节点，并且把新主节点的相关信息通知给从节点和客户端。

            哨兵一般是以集群的方式部署，至少需要 3 个哨兵节点，哨兵集群主要负责三件事情：监控、选主、通知。

            哨兵节点通过 Redis 的发布者/订阅者机制，哨兵之间可以相互感知，相互连接，然后组成哨兵集群，同时哨兵又通过 INFO 命令，在主节点里获得了所有从节点连接信息，于是就能和从节点建立连接，并进行监控了。

            1、第一轮投票：判断主节点下线

            当哨兵集群中的某个哨兵判定主节点下线（主观下线）后，就会向其他哨兵发起命令，其他哨兵收到这个命令后，就会根据自身和主节点的网络状况，做出赞成投票或者拒绝投票的响应。

            当这个哨兵的赞同票数达到哨兵配置文件中的 quorum 配置项设定的值后，这时主节点就会被该哨兵标记为「客观下线」。

            2、第二轮投票：选出哨兵 leader

            某个哨兵判定主节点客观下线后，该哨兵就会发起投票，告诉其他哨兵，它想成为 leader，想成为 leader 的哨兵节点，要满足两个条件：

            第一，拿到半数以上的赞成票；
            第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。
            3、由哨兵 leader 进行主从故障转移

            选举出了哨兵 leader 后，就可以进行主从故障转移的过程了。该操作包含以下四个步骤：

            第一步：在已下线主节点（旧主节点）属下的所有「从节点」里面，挑选出一个从节点，并将其转换为主节点，选择的规则：
            过滤掉已经离线的从节点；
            过滤掉历史网络连接状态不好的从节点；
            将剩下的从节点，进行三轮考察：优先级、复制进度、ID 号。在每一轮考察过程中，如果找到了一个胜出的从节点，就将其作为新主节点。
            第二步：让已下线主节点属下的所有「从节点」修改复制目标，修改为复制「新主节点」；
            第三步：将新主节点的 IP 地址和信息，通过「发布者/订阅者机制」通知给客户端；
            第四步：继续监视旧主节点，当这个旧主节点重新上线时，将它设置为新主节点的从节点；

    集群脑裂导致数据丢失怎么办？
    什么是脑裂？
        在 Redis 主从架构中，部署方式一般是「一主多从」，主节点提供写操作，从节点提供读操作。

        如果主节点的网络突然发生了问题，它与所有的从节点都失联了，但是此时的主节点和客户端的网络是正常的，这个客户端并不知道 Redis 内部已经出现了问题，还在照样的向这个失联的主节点写数据（过程A），此时这些数据被主节点缓存到了缓冲区里，因为主从节点之间的网络问题，这些数据都是无法同步给从节点的。

        这时，哨兵也发现主节点失联了，它就认为主节点挂了（但实际上主节点正常运行，只是网络出问题了），于是哨兵就会在从节点中选举出一个 leeder 作为主节点，这时集群就有两个主节点了 —— 脑裂出现了。

        这时候网络突然好了，哨兵因为之前已经选举出一个新主节点了，它就会把旧主节点降级为从节点（A），然后从节点（A）会向新主节点请求数据同步，因为第一次同步是全量同步的方式，此时的从节点（A）会清空掉自己本地的数据，然后再做全量同步。所以，之前客户端在过程 A 写入的数据就会丢失了，也就是集群产生脑裂数据丢失的问题。

        总结一句话就是：由于网络问题，集群节点之间失去联系。主从数据不同步；重新平衡选举，产生两个主服务。等网络恢复，旧主节点会降级为从节点，再与新主节点进行同步复制的时候，由于会从节点会清空自己的缓冲区，所以导致之前客户端写入的数据丢失了。

    Redis 使用的过期删除策略是什么？
    每当我们对一个 key 设置了过期时间时，Redis 会把该 key 带上过期时间存储到一个过期字典（expires dict）中，也就是说「过期字典」保存了数据库中所有 key 的过期时间。

    当我们查询一个 key 时，Redis 首先检查该 key 是否存在于过期字典中：

    如果不在，则正常读取键值；
    如果存在，则会获取该 key 的过期时间，然后与当前系统时间进行比对，如果比系统时间大，那就没有过期，否则判定该 key 已过期。

    Redis 使用的过期删除策略是「惰性删除+定期删除」这两种策略配和使用。

    惰性删除策略的做法是，不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。
    定期删除策略的做法是，每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。

    Redis 内存满了，会发生什么？
        在 Redis 的运行内存达到了某个阀值，就会触发内存淘汰机制，这个阀值就是我们设置的最大运行内存，此值在 Redis 的配置文件中可以找到，配置项为 maxmemory。
    Redis 内存淘汰策略有哪些？
    1. 不进行数据淘汰的策略
        allkeys-random：随机淘汰任意键值;
        allkeys-lru：淘汰整个键值中最久未使用的键值；
        allkeys-lfu（Redis 4.0 后新增的内存淘汰策略）：淘汰整个键值中最少使用的键值
    LRU 算法和 LFU 算法有什么区别？
        LRU 全称是 Least Recently Used 翻译为最近最少使用，会选择淘汰最近最少使用的数据。
        LFU 全称是 Least Frequently Used 翻译为最近最不常用的，LFU 算法是根据数据访问次数来淘汰数据的，它的核心思想是“如果数据过去被访问多次，那么将来被访问的频率也更高”。
    #### Redis 缓存设计
        - 缓存雪崩
            大量缓存数据在同一时间过期（失效）时，如果此时有大量的用户请求，都无法在 Redis 中处理，于是全部请求都直接访问数据库，从而导致数据库的压力骤增，严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃
            解决方法：
                造成雪崩的原因是同时过期， 解决方法是过期时间随机打散
        - 缓存击穿（热点数据）
            如果缓存中的某个热点数据过期了，此时大量的请求访问了该热点数据，就无法从缓存中读取，直接访问数据库，数据库很容易就被高并发的请求冲垮，这就是缓存击穿的问题。
            解决方法：
                不给热点数据设置过期时间，由后台异步更新缓存，或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间；
        - 缓存穿透（cache 没有数据，mysql 也没有数据）
            当用户访问的数据，既不在缓存中，也不在数据库中，导致请求在访问缓存时，发现缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据，没办法构建缓存数据，来服务后续的请求。那么当有大量这样的请求到来时，数据库的压力骤增，这就是缓存穿透的问题。
            造成的原因：
                业务误操作，缓存中的数据和数据库中的数据都被误删除了，所以导致缓存和数据库中都没有数据；
                黑客恶意攻击，故意大量访问某些读取不存在数据的业务；
            解决方法：
                主要是业务层面：
                    - 非法请求的限制：当有大量恶意请求访问不存在的数据的时候，也会发生缓存穿透，因此在 API 入口处我们要判断求请求参数是否合理，请求参数是否含有非法值、请求字段是否存在，如果判断出是恶意请求就直接返回错误，避免进一步访问缓存和数据库。
                    - 设置空值或者默认值：当我们线上业务发现缓存穿透的现象时，可以针对查询的数据，在缓存中设置一个空值或者默认值，这样后续请求就可以从缓存中读取到空值或者默认值，返回给应用，而不会继续查询数据库。

    #### redis实战
        #Redis 如何实现延迟队列？
        使用 zadd score1 value1 命令就可以一直往内存中生产消息。再利用 zrangebysocre 查询符合条件的所有待处理的任务， 通过循环执行队列任务即可。
    什么是 Redis 大 key？
        大 key 并不是指 key 的值很大，而是 key 对应的 value 很大。

        一般而言，下面这两种情况被称为大 key：

        String 类型的值大于 10 KB；
        Hash、List、Set、ZSet 类型的元素的个数超过 5000个；
    大 key 会造成什么问题？

        大 key 会带来以下四种影响：

        客户端超时阻塞。由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。
        引发网络阻塞。每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。
        阻塞工作线程。如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。
    如何找到大 key ？
        redis-cli --bigkeys 查找大key

    如何删除大 key？
        1、分批次删除
            删除大 Hash，使用 hscan 命令，每次获取 100 个字段，再用 hdel 命令，每次删除 1 个字段。
            对于删除大 List，通过 ltrim 命令，每次删除少量元素。
            删除大 Set，使用 sscan 命令，每次扫描集合中 100 个元素，再用 srem 命令每次删除一个键。
            删除大 ZSet，使用 zremrangebyrank 命令，每次删除 top 100个元素。
    #### 如何设计一个缓存策略，可以动态缓存热点数据呢？    


                
